{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "FEkWfnrIuFYI",
        "outputId": "1c7c87bb-6501-4868-ae50-db3228050eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langdetect\n",
        "!pip install contractions\n",
        "\n",
        "# Libraries for general purpose\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Text cleaning\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Data preprocessing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from langdetect import detect, LangDetectException\n",
        "import contractions\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Naive Bayes\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# PyTorch LSTM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Tokenization for LSTM\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Transformers library for BERT\n",
        "import transformers\n",
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import time\n",
        "\n",
        "# Set seed for reproducibility\n",
        "import random\n",
        "seed_value = 2042\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "# Set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.despine()\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)\n",
        "\n",
        "#\n",
        "text_col_name = 'clear_text'\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnrE--K1t-sb",
        "outputId": "2ee063b3-fab9-434f-d7b4-51d576557e97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "lenQFP39ulMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f583c572-9df8-4453-c4b7-1c3f17996f00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "nYPpZdH3CJtX"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8r5IP1xISXbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "226fa16d-769b-40b9-9a2a-9b1bb6f1e4d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo90Wo_n6MS8"
      },
      "source": [
        "## Text preprocess for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yETHEDbzy4L0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b55d77c2-a48e-4c6e-fdeb-2f5510d88e90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0       subject                 date label  \\\n",
              "0           0  politicsNews  2017-12-31 00:00:00  real   \n",
              "1           1  politicsNews  2017-12-29 00:00:00  real   \n",
              "2           2  politicsNews  2017-12-31 00:00:00  real   \n",
              "3           3  politicsNews  2017-12-30 00:00:00  real   \n",
              "4           4  politicsNews  2017-12-29 00:00:00  real   \n",
              "\n",
              "                                            all_text  \\\n",
              "0  As U.S. budget fight looms, Republicans flip t...   \n",
              "1  U.S. military to accept transgender recruits o...   \n",
              "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
              "3  FBI Russia probe helped by Australian diplomat...   \n",
              "4  Trump wants Postal Service to charge 'much mor...   \n",
              "\n",
              "                                          clear_text  \n",
              "0  as us budget fight looms republicans flip thei...  \n",
              "1  us military to accept transgender recruits on ...  \n",
              "2  senior us republican senator let mr mueller do...  \n",
              "3  fbi russia probe helped by australian diplomat...  \n",
              "4  trump wants postal service to charge much more...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37b8fd08-6939-42b2-acea-348ac77672ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "      <th>all_text</th>\n",
              "      <th>clear_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>2017-12-31 00:00:00</td>\n",
              "      <td>real</td>\n",
              "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
              "      <td>as us budget fight looms republicans flip thei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>2017-12-29 00:00:00</td>\n",
              "      <td>real</td>\n",
              "      <td>U.S. military to accept transgender recruits o...</td>\n",
              "      <td>us military to accept transgender recruits on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>2017-12-31 00:00:00</td>\n",
              "      <td>real</td>\n",
              "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
              "      <td>senior us republican senator let mr mueller do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>2017-12-30 00:00:00</td>\n",
              "      <td>real</td>\n",
              "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
              "      <td>fbi russia probe helped by australian diplomat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>2017-12-29 00:00:00</td>\n",
              "      <td>real</td>\n",
              "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
              "      <td>trump wants postal service to charge much more...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37b8fd08-6939-42b2-acea-348ac77672ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37b8fd08-6939-42b2-acea-348ac77672ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37b8fd08-6939-42b2-acea-348ac77672ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9f01fe1-95c8-4b90-9a99-ce3cd07d776d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9f01fe1-95c8-4b90-9a99-ce3cd07d776d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9f01fe1-95c8-4b90-9a99-ce3cd07d776d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "data = pd.read_csv('drive//MyDrive/data/Data.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mPc58yjI7ykZ"
      },
      "outputs": [],
      "source": [
        "def tokenize(data):\n",
        "    data['tokens'] = data.apply(lambda row: word_tokenize(row['clear_text'].lower()), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "YazlfIOlzBba"
      },
      "outputs": [],
      "source": [
        "data = data.replace({'label': {'real': 1, 'fake': 0}})\n",
        "tokenize(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "KEFuo01TzEBD"
      },
      "outputs": [],
      "source": [
        "X = data['clear_text'].to_list()\n",
        "\n",
        "data['label']\n",
        "y = data['label'].to_list()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "745iIJM2zFcJ"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "AbC1HBzizG21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0983b5f-21b7-422d-c23c-80a4908c4dda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0, 11175],\n",
              "       [    1, 13558]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "VSzpkjYBzs9w"
      },
      "outputs": [],
      "source": [
        "def sorted_corpus(data):\n",
        "    ##Create vocabulary of words from column\n",
        "    corpus = []\n",
        "    for text in data['tokens']:\n",
        "      corpus.extend(text)\n",
        "    count_words = Counter(corpus)\n",
        "    return count_words.most_common()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Nhg9Mx9a__Fk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "sPQOVIhT0aH1"
      },
      "outputs": [],
      "source": [
        "sorted_words = sorted_corpus(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ICW-upq92TC9"
      },
      "outputs": [],
      "source": [
        "def vocab_to_int(sorted_vocab, column):\n",
        "    vocab_to_int = {word:n+1 for n, (word, counter) in enumerate(sorted_words)}\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        article_num = [vocab_to_int[word] for word in text]\n",
        "        text_int.append(article_num)\n",
        "    return text_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ssR549dE3DVO"
      },
      "outputs": [],
      "source": [
        "text_int = vocab_to_int(sorted_words, data['tokens'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ZQbjTsFz4h_k"
      },
      "outputs": [],
      "source": [
        "def pad_tokens(text_int, seq_len):\n",
        "  ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for n, article in enumerate(text_int):\n",
        "        if len(article) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(article)))\n",
        "            new = zeros + article\n",
        "        else:\n",
        "            new = article[: seq_len]\n",
        "        features[n, :] = np.array(new)\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "pfo4Ys394wZM"
      },
      "outputs": [],
      "source": [
        "tokenized_column = pad_tokens(text_int, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "4-b2eNDd5yGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436c9fb3-4032-49ca-f67a-7a0cd68831d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38647, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "tokenized_column.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwOi3FaA5-IB"
      },
      "source": [
        "## Word2Vec Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "fqrSna2k54Mj"
      },
      "outputs": [],
      "source": [
        "Word2vec_train_data = list(map(lambda x: x.split(), X_train))\n",
        "EMBEDDING_DIM = 50\n",
        "word2vec_model = Word2Vec(Word2vec_train_data, vector_size=EMBEDDING_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "xILN-WwH8b-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6344c04-5b16-41bb-877e-3224e348e3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 226636\n"
          ]
        }
      ],
      "source": [
        "print(f\"Vocabulary size: {len(sorted_words) + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Z2vqMAzi8gno"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(sorted_words) + 1 #+1 for the padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "yC0HvURb_sQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83eb7863-6c68-4ff9-86e9-3b7fbaaf7bb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the', 864439)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "sorted_words[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "eQJ8-5498h6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db52b32-ca23-4b6b-8a5b-f7622ec51996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix Shape: (226636, 50)\n"
          ]
        }
      ],
      "source": [
        "# Define an empty embedding matrix of shape (VOCAB_SIZE, EMBEDDING_DIM)\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "\n",
        "# Fill the embedding matrix with pre-trained values from word2vec\n",
        "for n, (word, token) in enumerate(sorted_words):\n",
        "    # Check if the word is present in the word2vec model's vocabulary\n",
        "    if word in word2vec_model.wv.key_to_index:\n",
        "        # If the word is present, retrieve its embedding vector and add it to the embedding matrix\n",
        "        embedding_vector = word2vec_model.wv[word]\n",
        "        embedding_matrix[n] = embedding_vector\n",
        "\n",
        "# Print the shape of the embedding matrix\n",
        "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "AqqPRTgB9aoD"
      },
      "outputs": [],
      "source": [
        "X = tokenized_column\n",
        "y = data['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "qWdU8dQJAaQ8"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYLvMd0WA8li"
      },
      "source": [
        "## TORCH LOADER ALLELUJA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "IqCNK4CgA_pS"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "dRxNvKe0BDzw"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "heizjeXZBFHb"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "wj-lgdOyBG0W"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, is_bidirectional):\n",
        "        super(Attention, self).__init__()\n",
        "        self.is_bidirectional = is_bidirectional\n",
        "        # The attention linear layer which transforms the input data to the hidden space\n",
        "        self.attn = nn.Linear(hidden_dim * (4 if is_bidirectional else 2), hidden_dim * (2 if is_bidirectional else 1))\n",
        "        # The linear layer that calculates the attention scores\n",
        "        self.v = nn.Linear(hidden_dim * (2 if is_bidirectional else 1), 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        seq_len = encoder_outputs.size(1)\n",
        "        # Concatenate the last two hidden states in case of a bidirectional LSTM\n",
        "        if self.is_bidirectional:\n",
        "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=-1)\n",
        "        else:\n",
        "            hidden = hidden[-1]\n",
        "        # Repeat the hidden state across the sequence length\n",
        "        hidden_repeated = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = torch.tanh(self.attn(torch.cat((hidden_repeated, encoder_outputs), dim=2)))\n",
        "        # Compute attention scores\n",
        "        attn_weights = self.v(attn_weights).squeeze(2)\n",
        "        # Apply softmax to get valid probabilities\n",
        "        return nn.functional.softmax(attn_weights, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "OA6vvIFqBOEi"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LSTM_Classifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, lstm_layers, dropout, is_bidirectional):\n",
        "        super(LSTM_Classifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = lstm_layers\n",
        "        self.is_bidirectional = is_bidirectional\n",
        "\n",
        "        # The Embedding layer that converts input words to embeddings\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # LSTM layer which processes the embeddings\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, lstm_layers, batch_first=True, bidirectional=is_bidirectional)\n",
        "        # Attention layer to compute the context vector\n",
        "        self.attention = Attention(hidden_dim, is_bidirectional)\n",
        "        # Fully connected layer which classifies the context vector into classes\n",
        "        self.fc = nn.Linear(hidden_dim * (2 if is_bidirectional else 1), num_classes)\n",
        "        # Apply LogSoftmax to outputs for numerical stability\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        # Dropout layer for regularisation\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # Transform words to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "        # Pass embeddings to LSTM\n",
        "        out, hidden = self.lstm(embedded, hidden)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = self.attention(hidden[0], out)\n",
        "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
        "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
        "        # Classify the context vector\n",
        "        out = self.softmax(self.fc(context))\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # Factor determines the size of hidden states depending on bidirectionality\n",
        "        factor = 2 if self.is_bidirectional else 1\n",
        "        # Initial hidden and cell states are zero\n",
        "        h0 = torch.zeros(self.num_layers * factor, batch_size, self.hidden_dim).to(device)\n",
        "        c0 = torch.zeros(self.num_layers * factor, batch_size, self.hidden_dim).to(device)\n",
        "        return (h0, c0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "-qBN6qp4BR6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5395b4-fffe-4c6c-edcb-f8c07d5c7afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM_Classifier(\n",
            "  (embedding): Embedding(226636, 50)\n",
            "  (lstm): LSTM(50, 50, batch_first=True)\n",
            "  (attention): Attention(\n",
            "    (attn): Linear(in_features=100, out_features=50, bias=True)\n",
            "    (v): Linear(in_features=50, out_features=1, bias=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=50, out_features=2, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "NUM_CLASSES = 2 #We are dealing with a multiclass classification of 5 classes\n",
        "HIDDEN_DIM = 50 #number of neurons of the internal state (internal neural network in the LSTM)\n",
        "LSTM_LAYERS = 1 #Number of stacked LSTM layers\n",
        "\n",
        "IS_BIDIRECTIONAL = False # Set this to False for unidirectional LSTM, and True for bidirectional LSTM\n",
        "\n",
        "LR = 4e-4 #Learning rate\n",
        "DROPOUT = 0.5 #LSTM Dropout\n",
        "EPOCHS = 10 #Number of training epoch\n",
        "\n",
        "model = LSTM_Classifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_CLASSES, LSTM_LAYERS, DROPOUT, IS_BIDIRECTIONAL)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Initialize the embedding layer with the previously defined embedding matrix\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "# Allow the embedding matrix to be fine-tuned to better adapt to our dataset and get higher accuracy\n",
        "model.embedding.weight.requires_grad = True\n",
        "\n",
        "# Set up the criterion (loss function)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay = 5e-6)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "YKB1SbI0DKS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f6ef87-ecbb-4ef3-af5f-b9763c9c00f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:Validation accuracy increased (0.000000 --> 99.838083).  Saving model ...\n",
            "\tTrain_loss : 0.1023 Val_loss : 0.0117\n",
            "\tTrain_acc : 95.114% Val_acc : 99.838%\n",
            "Epoch 2:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0138 Val_loss : 0.0124\n",
            "\tTrain_acc : 99.761% Val_acc : 99.773%\n",
            "Epoch 3:Validation accuracy increased (99.838083 --> 99.854275).  Saving model ...\n",
            "\tTrain_loss : 0.0096 Val_loss : 0.0083\n",
            "\tTrain_acc : 99.781% Val_acc : 99.854%\n",
            "Epoch 4:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0065 Val_loss : 0.0098\n",
            "\tTrain_acc : 99.854% Val_acc : 99.790%\n",
            "Epoch 5:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0038 Val_loss : 0.0098\n",
            "\tTrain_acc : 99.915% Val_acc : 99.757%\n",
            "Epoch 6:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0030 Val_loss : 0.0069\n",
            "\tTrain_acc : 99.927% Val_acc : 99.838%\n",
            "Epoch 7:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0019 Val_loss : 0.0095\n",
            "\tTrain_acc : 99.960% Val_acc : 99.822%\n",
            "Epoch 8:Validation accuracy did not increase\n",
            "Early stopped at epoch : 8\n"
          ]
        }
      ],
      "source": [
        "total_step = len(train_loader)\n",
        "total_step_val = len(valid_loader)\n",
        "\n",
        "early_stopping_patience = 4\n",
        "early_stopping_counter = 0\n",
        "\n",
        "valid_acc_max = 0 # Initialize best accuracy top 0\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "\n",
        "    #lists to host the train and validation losses of every batch for each epoch\n",
        "    train_loss, valid_loss  = [], []\n",
        "    #lists to host the train and validation accuracy of every batch for each epoch\n",
        "    train_acc, valid_acc  = [], []\n",
        "\n",
        "    #lists to host the train and validation predictions of every batch for each epoch\n",
        "    y_train_list, y_val_list = [], []\n",
        "\n",
        "    #initalize number of total and correctly classified texts during training and validation\n",
        "    correct, correct_val = 0, 0\n",
        "    total, total_val = 0, 0\n",
        "    running_loss, running_loss_val = 0, 0\n",
        "\n",
        "\n",
        "    ####TRAINING LOOP####\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device) #load features and targets in device\n",
        "\n",
        "        h = model.init_hidden(labels.size(0))\n",
        "\n",
        "        model.zero_grad() #reset gradients\n",
        "\n",
        "        output, h = model(inputs,h) #get output and hidden states from LSTM network\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred_train = torch.argmax(output, dim=1) #get tensor of predicted values on the training set\n",
        "        y_train_list.extend(y_pred_train.squeeze().tolist()) #transform tensor to list and the values to the list\n",
        "\n",
        "        correct += torch.sum(y_pred_train==labels).item() #count correctly classified texts per batch\n",
        "        total += labels.size(0) #count total texts per batch\n",
        "\n",
        "    train_loss.append(running_loss / total_step)\n",
        "    train_acc.append(100 * correct / total)\n",
        "\n",
        "    ####VALIDATION LOOP####\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            val_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "\n",
        "            val_loss = criterion(output, labels)\n",
        "            running_loss_val += val_loss.item()\n",
        "\n",
        "            y_pred_val = torch.argmax(output, dim=1)\n",
        "            y_val_list.extend(y_pred_val.squeeze().tolist())\n",
        "\n",
        "            correct_val += torch.sum(y_pred_val==labels).item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "        valid_loss.append(running_loss_val / total_step_val)\n",
        "        valid_acc.append(100 * correct_val / total_val)\n",
        "\n",
        "    #Save model if validation accuracy increases\n",
        "    if np.mean(valid_acc) >= valid_acc_max:\n",
        "        torch.save(model.state_dict(), './state_dict.pt')\n",
        "        print(f'Epoch {e+1}:Validation accuracy increased ({valid_acc_max:.6f} --> {np.mean(valid_acc):.6f}).  Saving model ...')\n",
        "        valid_acc_max = np.mean(valid_acc)\n",
        "        early_stopping_counter=0 #reset counter if validation accuracy increases\n",
        "    else:\n",
        "        print(f'Epoch {e+1}:Validation accuracy did not increase')\n",
        "        early_stopping_counter+=1 #increase counter if validation accuracy does not increase\n",
        "\n",
        "    if early_stopping_counter > early_stopping_patience:\n",
        "        print('Early stopped at epoch :', e+1)\n",
        "        break\n",
        "\n",
        "    print(f'\\tTrain_loss : {np.mean(train_loss):.4f} Val_loss : {np.mean(valid_loss):.4f}')\n",
        "    print(f'\\tTrain_acc : {np.mean(train_acc):.3f}% Val_acc : {np.mean(valid_acc):.3f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "KvlInHRyDjJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf5a62a-adbc-4282-d5ca-d657bf02f77c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Loading the best model\n",
        "model.load_state_dict(torch.load('./state_dict.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "PsztOK90h5cv"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    y_pred_list = []\n",
        "    y_test_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            test_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "            output, val_h = model(inputs, test_h)\n",
        "            y_pred_test = torch.argmax(output, dim=1)\n",
        "            y_pred_list.extend(y_pred_test.squeeze().tolist())\n",
        "            y_test_list.extend(labels.squeeze().tolist())\n",
        "\n",
        "    return y_pred_list, y_test_list\n",
        "\n",
        "y_pred_list, y_test_list = evaluate_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "e2uuoO1siNwc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Y0Ko9PfwiM5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77962e39-a29d-4b2e-b2ec-77a45a294eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Bi-LSTM :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        fake       1.00      1.00      1.00      3485\n",
            "        true       1.00      1.00      1.00      4227\n",
            "\n",
            "    accuracy                           1.00      7712\n",
            "   macro avg       1.00      1.00      1.00      7712\n",
            "weighted avg       1.00      1.00      1.00      7712\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Classification Report for Bi-LSTM :\\n', classification_report(y_test_list, y_pred_list, target_names=['fake', 'true']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_article = \"Philosophers amongst you will be familiar with the work of Rene Descartes – a mathematician, epistemologist, and rationalist – much of his work laid the ground for modern philosophy and in particular the strand that has grown out of Hobbes and Locke that informs a lot of the 17th century and the formation of states and societies thereafter. \\\n",
        "There is one eerie and unsettling aspect of his life that is gaining greater attention. Descartes had a relationship with a servant (Helen van der Strom), and their relationship produced a young daughter Francine, to whom Descartes was very attached. Tragically, Francine died of scarlet fever, aged five, and so distraught was Descartes that he had a robot or automata (clockwork, lifelike doll) built in her likeness.\\\n",
        "He transported this ‘doll’ with him whenever he travelled (in a casket), and on a trip to visit Queen Christina of Sweden, the crew of the ship on which he was travelling became so alarmed (it was a stormy night) by the robot and Descartes murmurings with it, that they invaded his quarters, seized and broke the ‘doll’ and threw it overboard. Descartes was further traumatized, and whilst it is not clear the incident immediately impacted his health, he died soon after.\\\n",
        "Technology scares us Descartes ‘doll’ is enjoying renewed attention for what it suggests about the relations between humans and machines, how robots can potentially replace and even supplant humans in different ways and for the manner in which this can cause consternation.\\\n",
        "The relationship between human and machine is a theme that will cut through the advance (or decline) of the world, and we have written about it frequently (i.e. ‘Talos’). As my limited vision can perceive, will attempt a classification that says there are at least two aspects of this megatrend – the risks that machines take over our (human) world (AI), and the risks that machine led worlds start to exist outside the human one (Defi, Web3/metaverse).\\\n",
        "The bad news is that in the case of the former, there is an unknown risk that machines could injure the human race (weaponized AI, the use of AI by ‘bad’ humans and the use of robots in war not to mention the creation of chemical and biological weapons by AI that I referred to in ‘The Final Problem’)\""
      ],
      "metadata": {
        "id": "qiyOMKrJStYJ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vocab_to_int_one(sorted_vocab, text):\n",
        "    vocab_to_int = {word:n+1 for n, (word, counter) in enumerate(sorted_words)}\n",
        "    text_int = []\n",
        "    for word in text:\n",
        "      try:\n",
        "        text_int.append(vocab_to_int[word])\n",
        "      except KeyError:\n",
        "        continue\n",
        "    return text_int\n",
        "\n",
        "\n",
        "def pad_tokens_one(article, seq_len):\n",
        "  ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    if len(article) <= seq_len:\n",
        "        zeros = list(np.zeros(seq_len - len(article)))\n",
        "        new = zeros + article\n",
        "    else:\n",
        "        new = article[: seq_len]\n",
        "    return new\n",
        "\n",
        "def text_preprocess(txt, sorted_vocab):\n",
        "    txt_int = vocab_to_int_one(sorted_vocab, test_article)\n",
        "    ready = pad_tokens_one(txt_int, 50)\n",
        "    return ready\n"
      ],
      "metadata": {
        "id": "QRzHZEPcWH85"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_article_int = text_preprocess(test_article, sorted_words)"
      ],
      "metadata": {
        "id": "1VM1aC8Hc4Xk"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "LughJhAWifn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60953b25-1db6-4e31-adf7-666bac4fbee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0.]]], device='cuda:0'),\n",
              " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0.]]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "test_h = model.init_hidden(1)\n",
        "input = torch.LongTensor([test_article_int]).to(device)\n",
        "# test_h = (torch.zeros(1, 50).to(device), torch.zeros(1, 50).to(device))\n",
        "\n",
        "test_h\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, val_h = model(input, test_h)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_ZfBerAiu_2",
        "outputId": "dec67546-4326-4df5-c722-7966507f86a2"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.9117e-04, -7.8466e+00]], device='cuda:0',\n",
              "       grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = torch.argmax(output, dim=1)"
      ],
      "metadata": {
        "id": "94SQm3XhivEf"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhPVV9S8Uo9U",
        "outputId": "7066ed55-033d-46f1-d487-e59e770d53e2"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, txt, sorted_words):\n",
        "    txt_int = text_preprocess(txt, sorted_words)\n",
        "    test_h = model.init_hidden(1)\n",
        "    input = torch.LongTensor([test_article_int]).to(device)\n",
        "    output, val_h = model(input, test_h)\n",
        "    y_pred_test = int(torch.argmax(output, dim=1))\n",
        "    return 'fake' if  y_pred_test==0 else 'true'\n",
        "\n",
        "predict(model, test_article, sorted_words)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mj3yBsxDm3pW",
        "outputId": "d34733bf-ab7b-4f85-8310-69accb9efe8a"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fake'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}